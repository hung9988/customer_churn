{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107 0 1 26 13.7 3 3.7 1 329 55.540000000000006 611.5 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df =pd.read_csv('train.csv')\n",
    "\n",
    "### UNCOMMENT THIS PART TO USE THE FEATURE ENGINEERING\n",
    "df['total_call'] = df['total_day_calls'] + df['total_eve_calls'] + df['total_night_calls']\n",
    "\n",
    "# Create 'total_charges' feature\n",
    "df['total_charges'] = df['total_day_charge'] + df['total_eve_charge'] + df['total_night_charge']\n",
    "\n",
    "# Create 'total_minutes' feature\n",
    "df['total_minutes'] = df['total_day_minutes'] + df['total_eve_minutes'] + df['total_night_minutes']\n",
    "df = df.drop(['total_day_calls', 'total_eve_calls', 'total_night_calls'], axis=1)\n",
    "\n",
    "# Delete contributing features for 'total_charges'\n",
    "df = df.drop(['total_day_charge', 'total_eve_charge', 'total_night_charge'], axis=1)\n",
    "\n",
    "# Delete contributing features for 'total_minutes'\n",
    "df = df.drop(['total_day_minutes', 'total_eve_minutes', 'total_night_minutes'], axis=1)\n",
    "\n",
    "\n",
    "df.drop(['state','area_code'], axis=1, inplace=True)\n",
    "# df.drop(['state', 'area_code', 'account_length'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "###################\n",
    "\n",
    "###ONE HOT ENCODING\n",
    "\n",
    "\n",
    "# df = pd.get_dummies(df, columns=['area_code'])\n",
    "\n",
    "\n",
    "### MOVING THE Y VARIABLE TO THE END\n",
    "churn = df['churn']\n",
    "df = df.drop('churn', axis=1)\n",
    "df['churn'] = churn\n",
    "\n",
    "\n",
    "data=np.array(df)\n",
    "\n",
    "\n",
    "data[data=='no']=0\n",
    "data[data=='yes']=1\n",
    "data[data==False]=0\n",
    "data[data==True]=1\n",
    "print(data[0])\n",
    "X=data[:,:-1]\n",
    "y=data[:,-1]\n",
    "\n",
    "\n",
    "\n",
    "### SPLITTING THE DATA INTO TRAIN, VALIDATION AND TEST SETS\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42) \n",
    "\n",
    "###DATA NORMALIZATION\n",
    "def normalize(X):\n",
    "    X = X.astype(float)\n",
    "    X=(X-X.mean(axis=0))/X.std(axis=0)\n",
    "    return X\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_val = normalize(X_val)\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "\n",
    "#SMOTE, oversampling the minority class (will read more about this later)\n",
    "X_train_oversampled_smote = []\n",
    "labels_train_oversampled_smote = []\n",
    "indices_0 = np.where(y_train == 0)[0]\n",
    "indices_1 = np.where(y_train == 1)[0]\n",
    "indices = np.concatenate([indices_0, indices_1])\n",
    "for _ in range(X_train.shape[0]):\n",
    "    p = np.random.random()\n",
    "    #sample from majority class\n",
    "    if p < 0.5:\n",
    "        X_train_oversampled_smote.append(X_train[np.random.choice(indices_0)])\n",
    "        labels_train_oversampled_smote.append(0)\n",
    "    #sample from minority class\n",
    "    else:\n",
    "        #get two random samples from minority class\n",
    "        minority_samp_1 = X_train[np.random.choice(indices_1)]\n",
    "        minority_samp_2 = X_train[np.random.choice(indices_1)]\n",
    "        \n",
    "        #get random proportion with which to mix them\n",
    "        prop = np.random.random()\n",
    "        \n",
    "        #generate synthetic sample from minority class\n",
    "        synthetic_minority_samp = prop*minority_samp_1 + (1-prop)*minority_samp_2\n",
    "        X_train_oversampled_smote.append(synthetic_minority_samp)\n",
    "        labels_train_oversampled_smote.append(1)\n",
    "        \n",
    "X_train_with_SMOTE = np.array(X_train_oversampled_smote)\n",
    "y_train_with_SMOTE = np.array(labels_train_oversampled_smote)\n",
    "\n",
    "X_train_with_SMOTE = X_train_with_SMOTE.astype(np.float32)\n",
    "y_train_with_SMOTE = y_train_with_SMOTE.astype(np.float32)\n",
    "y_train_with_SMOTE = y_train_with_SMOTE.reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "###CONVERT TO APPROPIATE FORMAT\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "y_train = y_train.reshape(-1,)\n",
    "y_val = y_val.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "####\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.382133995037221\n",
      "Index(['account_length', 'international_plan', 'voice_mail_plan',\n",
      "       'number_vmail_messages', 'total_intl_minutes', 'total_intl_calls',\n",
      "       'total_intl_charge', 'number_customer_service_calls', 'total_call',\n",
      "       'total_charges', 'total_minutes', 'churn'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2975.0000</td>\n",
       "      <td>2975.0000</td>\n",
       "      <td>2975.0000</td>\n",
       "      <td>2975.0000</td>\n",
       "      <td>2975.0000</td>\n",
       "      <td>2975.0000</td>\n",
       "      <td>2975.0000</td>\n",
       "      <td>2975.0000</td>\n",
       "      <td>2975.0000</td>\n",
       "      <td>2975.0000</td>\n",
       "      <td>2975.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0002</td>\n",
       "      <td>1.0002</td>\n",
       "      <td>1.0002</td>\n",
       "      <td>1.0002</td>\n",
       "      <td>1.0002</td>\n",
       "      <td>1.0002</td>\n",
       "      <td>1.0002</td>\n",
       "      <td>1.0002</td>\n",
       "      <td>1.0002</td>\n",
       "      <td>1.0002</td>\n",
       "      <td>1.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.5089</td>\n",
       "      <td>-0.3185</td>\n",
       "      <td>-0.5940</td>\n",
       "      <td>-0.5668</td>\n",
       "      <td>-3.7385</td>\n",
       "      <td>-1.8153</td>\n",
       "      <td>-3.7393</td>\n",
       "      <td>-1.1951</td>\n",
       "      <td>-3.2346</td>\n",
       "      <td>-3.5775</td>\n",
       "      <td>-3.2702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.6964</td>\n",
       "      <td>-0.3185</td>\n",
       "      <td>-0.5940</td>\n",
       "      <td>-0.5668</td>\n",
       "      <td>-0.6378</td>\n",
       "      <td>-0.5907</td>\n",
       "      <td>-0.6317</td>\n",
       "      <td>-0.4255</td>\n",
       "      <td>-0.6886</td>\n",
       "      <td>-0.6898</td>\n",
       "      <td>-0.6775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.0167</td>\n",
       "      <td>-0.3185</td>\n",
       "      <td>-0.5940</td>\n",
       "      <td>-0.5668</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>-0.1825</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>-0.4255</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.6629</td>\n",
       "      <td>-0.3185</td>\n",
       "      <td>1.6834</td>\n",
       "      <td>0.5535</td>\n",
       "      <td>0.6390</td>\n",
       "      <td>0.6339</td>\n",
       "      <td>0.6383</td>\n",
       "      <td>0.3440</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>0.6803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.5830</td>\n",
       "      <td>3.1397</td>\n",
       "      <td>1.6834</td>\n",
       "      <td>3.1676</td>\n",
       "      <td>3.3020</td>\n",
       "      <td>6.3489</td>\n",
       "      <td>3.3000</td>\n",
       "      <td>5.7310</td>\n",
       "      <td>3.1882</td>\n",
       "      <td>3.5201</td>\n",
       "      <td>3.3181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1          2          3          4          5   \\\n",
       "count  2975.0000  2975.0000  2975.0000  2975.0000  2975.0000  2975.0000   \n",
       "mean      0.0000    -0.0000     0.0000    -0.0000     0.0000     0.0000   \n",
       "std       1.0002     1.0002     1.0002     1.0002     1.0002     1.0002   \n",
       "min      -2.5089    -0.3185    -0.5940    -0.5668    -3.7385    -1.8153   \n",
       "25%      -0.6964    -0.3185    -0.5940    -0.5668    -0.6378    -0.5907   \n",
       "50%      -0.0167    -0.3185    -0.5940    -0.5668     0.0189    -0.1825   \n",
       "75%       0.6629    -0.3185     1.6834     0.5535     0.6390     0.6339   \n",
       "max       3.5830     3.1397     1.6834     3.1676     3.3020     6.3489   \n",
       "\n",
       "              6          7          8          9          10  \n",
       "count  2975.0000  2975.0000  2975.0000  2975.0000  2975.0000  \n",
       "mean      0.0000    -0.0000     0.0000     0.0000     0.0000  \n",
       "std       1.0002     1.0002     1.0002     1.0002     1.0002  \n",
       "min      -3.7393    -1.1951    -3.2346    -3.5775    -3.2702  \n",
       "25%      -0.6317    -0.4255    -0.6886    -0.6898    -0.6775  \n",
       "50%       0.0168    -0.4255     0.0057     0.0104     0.0222  \n",
       "75%       0.6383     0.3440     0.6711     0.6612     0.6803  \n",
       "max       3.3000     5.7310     3.1882     3.5201     3.3181  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df =pd.read_csv('train.csv')\n",
    "\n",
    "### UNCOMMENT THIS PART TO USE THE FEATURE ENGINEERING\n",
    "df['total_call'] = df['total_day_calls'] + df['total_eve_calls'] + df['total_night_calls']\n",
    "\n",
    "# Create 'total_charges' feature\n",
    "df['total_charges'] = df['total_day_charge'] + df['total_eve_charge'] + df['total_night_charge']\n",
    "\n",
    "# Create 'total_minutes' feature\n",
    "df['total_minutes'] = df['total_day_minutes'] + df['total_eve_minutes'] + df['total_night_minutes']\n",
    "df = df.drop(['total_day_calls', 'total_eve_calls', 'total_night_calls'], axis=1)\n",
    "\n",
    "# Delete contributing features for 'total_charges'\n",
    "df = df.drop(['total_day_charge', 'total_eve_charge', 'total_night_charge'], axis=1)\n",
    "\n",
    "# Delete contributing features for 'total_minutes'\n",
    "df = df.drop(['total_day_minutes', 'total_eve_minutes', 'total_night_minutes'], axis=1)\n",
    "\n",
    "\n",
    "df.drop(['state','area_code'], axis=1, inplace=True)\n",
    "# df.drop(['state', 'area_code', 'account_length'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "###################\n",
    "\n",
    "###ONE HOT ENCODING\n",
    "\n",
    "\n",
    "# df = pd.get_dummies(df, columns=['area_code'])\n",
    "\n",
    "\n",
    "### MOVING THE Y VARIABLE TO THE END\n",
    "churn = df['churn']\n",
    "df = df.drop('churn', axis=1)\n",
    "df['churn'] = churn\n",
    "\n",
    "\n",
    "data=np.array(df)\n",
    "\n",
    "\n",
    "data[data=='no']=0\n",
    "data[data=='yes']=1\n",
    "data[data==False]=0\n",
    "data[data==True]=1\n",
    "\n",
    "X=data[:,:-1]\n",
    "y=data[:,-1]\n",
    "\n",
    "\n",
    "\n",
    "### SPLITTING THE DATA INTO TRAIN, VALIDATION AND TEST SETS\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42) \n",
    "\n",
    "###DATA NORMALIZATION\n",
    "def normalize(X):\n",
    "    X = X.astype(float)\n",
    "    X=(X-X.mean(axis=0))/X.std(axis=0)\n",
    "    return X\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_val = normalize(X_val)\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "\n",
    "#SMOTE, oversampling the minority class (will read more about this later)\n",
    "X_train_oversampled_smote = []\n",
    "labels_train_oversampled_smote = []\n",
    "indices_0 = np.where(y_train == 0)[0]\n",
    "indices_1 = np.where(y_train == 1)[0]\n",
    "indices = np.concatenate([indices_0, indices_1])\n",
    "for _ in range(X_train.shape[0]):\n",
    "    p = np.random.random()\n",
    "    #sample from majority class\n",
    "    if p < 0.5:\n",
    "        X_train_oversampled_smote.append(X_train[np.random.choice(indices_0)])\n",
    "        labels_train_oversampled_smote.append(0)\n",
    "    #sample from minority class\n",
    "    else:\n",
    "        #get two random samples from minority class\n",
    "        minority_samp_1 = X_train[np.random.choice(indices_1)]\n",
    "        minority_samp_2 = X_train[np.random.choice(indices_1)]\n",
    "        \n",
    "        #get random proportion with which to mix them\n",
    "        prop = np.random.random()\n",
    "        \n",
    "        #generate synthetic sample from minority class\n",
    "        synthetic_minority_samp = prop*minority_samp_1 + (1-prop)*minority_samp_2\n",
    "        X_train_oversampled_smote.append(synthetic_minority_samp)\n",
    "        labels_train_oversampled_smote.append(1)\n",
    "        \n",
    "X_train_with_SMOTE = np.array(X_train_oversampled_smote)\n",
    "y_train_with_SMOTE = np.array(labels_train_oversampled_smote)\n",
    "\n",
    "X_train_with_SMOTE = X_train_with_SMOTE.astype(np.float32)\n",
    "y_train_with_SMOTE = y_train_with_SMOTE.astype(np.float32)\n",
    "y_train_with_SMOTE = y_train_with_SMOTE.reshape(-1,1)\n",
    "\n",
    "def get_precisions_recalls(actual, preds):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    precision_0 = np.sum((actual == 0) & (preds == 0)) / np.sum(preds == 0)\n",
    "    precision_1 = np.sum((actual == 1) & (preds == 1)) / np.sum(preds == 1)\n",
    "    \n",
    "    plt.bar([0,1], [precision_0, precision_1])\n",
    "    plt.xticks([0,1], ['Class 0', 'Class 1'], fontsize=20)\n",
    "    plt.yticks(np.arange(0,1.1,0.1), fontsize=14)\n",
    "    plt.ylabel('Precision', fontsize=20)\n",
    "    plt.title(f'Precision Class 0: {round(precision_0,2)}\\nPrecision Class 1: {round(precision_1,2)}', fontsize=20)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    recall_0 = np.sum((actual == 0) & (preds == 0)) / np.sum(actual == 0)\n",
    "    recall_1 = np.sum((actual == 1) & (preds == 1)) / np.sum(actual == 1)\n",
    "    \n",
    "    plt.bar([0,1], [recall_0, recall_1])\n",
    "    plt.xticks([0,1], ['Class 0', 'Class 1'], fontsize=20)\n",
    "    plt.yticks(np.arange(0,1.1,0.1), fontsize=14)\n",
    "    plt.ylabel('Recall', fontsize=20)\n",
    "    plt.title(f'Recall Class 0: {round(recall_0,2)}\\nRecall Class 1: {round(recall_1,2)}', fontsize=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "####OVERSAMPLING THE MINORITY CLASS\n",
    "weight_minority_class = np.sum(y_train == 0) / np.sum(y_train == 1)\n",
    "print(weight_minority_class)\n",
    "\n",
    "X_train_oversampled = []\n",
    "y_train_oversampled = []\n",
    "\n",
    "indices_0 = np.where(y_train == 0)[0]\n",
    "indices_1 = np.where(y_train == 1)[0]\n",
    "indices = np.concatenate([indices_0, indices_1])\n",
    "\n",
    "#get weights for each class\n",
    "weights = np.empty(y_train.shape[0])\n",
    "weights[:indices_0.shape[0]] = 1\n",
    "weights[indices_0.shape[0]:] = weight_minority_class\n",
    "weights = weights/np.sum(weights)\n",
    "\n",
    "#sample new indices\n",
    "sampled_indices = np.random.choice(indices, indices.shape[0], p=weights)\n",
    "X_train_oversampled = X_train[sampled_indices]\n",
    "y_train_oversampled = y_train[sampled_indices]\n",
    "\n",
    "\n",
    "###CONVERT TO APPROPIATE FORMAT\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_val = y_val.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "####\n",
    "\n",
    "unique_rows = np.unique(X_train_oversampled, axis=0)\n",
    "num_unique_rows = unique_rows.shape[0]\n",
    "\n",
    "X_train.shape\n",
    "print(df.columns)\n",
    "pd.DataFrame(X_train).describe().map(lambda x: format(x, '.4f'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_with_SMOTE=0.8259026687598116\n",
    "avg_without_SMOTE=0.9161695447409735\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Values\n",
    "avg_with_SMOTE = 0.8259026687598116\n",
    "avg_without_SMOTE = 0.9161695447409735\n",
    "\n",
    "# Calculate difference\n",
    "difference = avg_without_SMOTE - avg_with_SMOTE\n",
    "\n",
    "# Plot\n",
    "plt.bar(['avg_acc_with_SMOTE', 'avg_acc_without_SMOTE'], [avg_with_SMOTE, avg_without_SMOTE])\n",
    "\n",
    "plt.ylabel('Average')\n",
    "plt.title('')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the dataframe\n",
    "df.plot(x='Name', y='Age', kind='bar')\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig('plot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most important features are:\n",
      "account_length: 0.041\n",
      "international_plan: 0.084\n",
      "voice_mail_plan: 0.037\n",
      "number_vmail_messages: 0.042\n",
      "total_intl_minutes: 0.048\n",
      "total_intl_calls: 0.064\n",
      "total_intl_charge: 0.052\n",
      "number_customer_service_calls: 0.143\n",
      "total_call: 0.036\n",
      "total_charges: 0.327\n",
      "total_minutes: 0.126\n",
      "The accuracy of the model is 0.962\n",
      "The accuracy of the model on the validation set is: 0.962\n",
      "The accuracy of the model on the test set is: 0.969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Print the name of the most important features\n",
    "print(\"The 5 most important features are:\")\n",
    "for feature, importance in zip(df.columns, rf.feature_importances_):\n",
    "    print(f\"{feature}: {importance:.3f}\")\n",
    "    \n",
    "# Print the accuracy of the model\n",
    "print(f\"The accuracy of the model is {rf.score(X_val, y_val):.3f}\")\n",
    "\n",
    "# Test the model on the validation set\n",
    "val_accuracy = rf.score(X_val, y_val)\n",
    "print(f\"The accuracy of the model on the validation set is: {val_accuracy:.3f}\")\n",
    "\n",
    "# Test the model on the test set\n",
    "test_accuracy = rf.score(X_test, y_test)\n",
    "print(f\"The accuracy of the model on the test set is: {test_accuracy:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df =pd.read_csv('test.csv')\n",
    "\n",
    "### UNCOMMENT THIS PART TO USE THE FEATURE ENGINEERING\n",
    "df['total_call'] = df['total_day_calls'] + df['total_eve_calls'] + df['total_night_calls']\n",
    "\n",
    "# Create 'total_charges' feature\n",
    "df['total_charges'] = df['total_day_charge'] + df['total_eve_charge'] + df['total_night_charge']\n",
    "\n",
    "# Create 'total_minutes' feature\n",
    "df['total_minutes'] = df['total_day_minutes'] + df['total_eve_minutes'] + df['total_night_minutes']\n",
    "df = df.drop(['total_day_calls', 'total_eve_calls', 'total_night_calls'], axis=1)\n",
    "\n",
    "# Delete contributing features for 'total_charges'\n",
    "df = df.drop(['total_day_charge', 'total_eve_charge', 'total_night_charge'], axis=1)\n",
    "\n",
    "# Delete contributing features for 'total_minutes'\n",
    "df = df.drop(['total_day_minutes', 'total_eve_minutes', 'total_night_minutes'], axis=1)\n",
    "\n",
    "\n",
    "df.drop(['state','id','area_code'], axis=1, inplace=True)\n",
    "# df.drop(['state', 'area_code', 'account_length'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "###################\n",
    "\n",
    "###ONE HOT ENCODING\n",
    "# df = pd.get_dummies(df, columns=['area_code'])\n",
    "\n",
    "###################\n",
    "\n",
    "###ONE HOT ENCODING\n",
    "#df = pd.get_dummies(df, columns=['area_code','state'])\n",
    "\n",
    "\n",
    "### MOVING THE Y VARIABLE TO THE END\n",
    "\n",
    "\n",
    "data=np.array(df)\n",
    "\n",
    "\n",
    "data[data=='no']=0\n",
    "data[data=='yes']=1\n",
    "data[data==False]=0\n",
    "data[data==True]=1\n",
    "X=data\n",
    "\n",
    "\n",
    "### SPLITTING THE DATA INTO TRAIN, VALIDATION AND TEST SETS\n",
    "\n",
    "###DATA NORMALIZATION\n",
    "def normalize(X):\n",
    "    X = X.astype(np.float32)\n",
    "    X=(X-X.mean(axis=0))/X.std(axis=0)\n",
    "    return X\n",
    "X=normalize(X)\n",
    "\n",
    "y_pred = rf.predict(X)\n",
    "print(y_pred)\n",
    "y_pred=np.where(y_pred==1,'yes','no')\n",
    "id_column = np.arange(1, y_pred.shape[0] + 1)\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df_output = pd.DataFrame({\n",
    "    'id': id_column,\n",
    "    'churn': y_pred\n",
    "})\n",
    "\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df_output.to_csv('output_rf.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
